{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "723e72a5",
   "metadata": {},
   "source": [
    "# Tutorial: Training Data Generation for Projection Upsampling Network\n",
    "\n",
    "## Overview\n",
    "This notebook presents a comprehensive walkthrough of the training data generation process for 2D SIM reconstruction. The approach focuses on generating paired datasets consisting of noisy inputs and corresponding high-quality SIM reconstruction images derived from 3D raw microscope data.\n",
    "\n",
    "## Objectives\n",
    "- **Dataset Creation:** Develop pairs comprising noisy raw images and ground-truth images obtained with high signal-to-noise ratio (SNR).\n",
    "- **Data Source:** Utilize the Microtubules dataset from BioSR for demonstration purposes. More details can be found at the [BioSR website](https://figshare.com/articles/dataset/BioSR/13264793).\n",
    "- **Dataset Size:** For the demonstration, a small dataset with 5 patches per sample is generated. In practical scenarios, a larger dataset is recommended.\n",
    "- **Tool Utilization:** Employ the CSBDeep library to streamline the data generation process. More information is available on the [CSBDeep documentation](https://csbdeep.bioimagecomputing.com/doc/).\n",
    "\n",
    "## Steps\n",
    "1. **Data Preparation:** Process the raw 3D noisy microscope data.\n",
    "2. **Pair Generation:** Create paired samples, aligning noisy data with corresponding ground-truth SIM reconstruction images.\n",
    "3. **Data Augmentation:** Apply augmentation techniques to enhance dataset variability and robustness. (saves on disk)\n",
    "4. **Analysis and Validation:** Assess the quality of generated pairs using visualization and statistical metrics.\n",
    "\n",
    "## Conclusion\n",
    "This structured guide details the procedures for generating training data essential for developing projection upsampling networks, specifically optimized for 2D SIM reconstruction tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826abc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# install the projection_upsampling_network package if already not installed\n",
    "%pip install projection_upsampling_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a7568f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/a/asarker/.conda/envs/thesis/lib/python3.10/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from projection_upsampling_network.data_gen import create_folders_SR, create_patches_reduced_target, RawDataScaled\n",
    "from csbdeep.utils import plot_some\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import os\n",
    "from projection_upsampling_network.augmentation import flip_up_down, flip_left_right, transpose,  rotate_90, rotate_180, rotate_270\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6504742",
   "metadata": {},
   "source": [
    "### Data Stracture\n",
    "\n",
    "- Place your data inside the \"dataset\" folder. \n",
    "- Divide it into three separate folders: train, test, and validation. \n",
    "- Each folder should contain files organized by cell (e.g., Cell_xx → files).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f3483",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Create Validation Dataset\n",
    "- we isolate training, testing and validation cells completely for make sure the data is unique. \n",
    "- Note: the number of patches are much smaller as we are creating a very small dataset for tutorial purpose only. \n",
    "- for real training, the number of patches needs to be much larger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf067c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================\n",
      "    5 raw images x    1 transformations   =     5 images\n",
      "    5 images     x    5 patches per image =    25 patches in total\n",
      "==================================================================\n",
      "Input data:\n",
      "dataset/microtubules/train/Train/SR: target='GT', sources=['Raw'], axes='ZYX', pattern='*.tif*'\n",
      "==================================================================\n",
      "Transformations:\n",
      "1 x Broadcast target image to the shape of source\n",
      "==================================================================\n",
      "128 x 128\n",
      "Patch size:\n",
      "9 x 128 x 128\n",
      "==================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:39<00:00,  7.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to dataset/microtubules/train/Train/SR/microtubules_SR_trainig.npz.\n",
      "Number of files in Raw Folder: 5\n",
      "Number of files in GT Folder: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "root_dir = 'dataset/microtubules/train'\n",
    "create_folders_SR(root_dir, gt_filename=\"SIM_gt\",\n",
    "    raw_filename=\"RawSIMData_level_02\")\n",
    "\n",
    "# define parameter for creating image patches\n",
    "scale_gt = 2.0\n",
    "patch_size = 256 \n",
    "n_patches_per_image = 5\n",
    "\n",
    "# create image patches for trainig . \n",
    "raw_data = RawDataScaled.from_folder (\n",
    "    basepath    = f'{root_dir}/Train/SR',\n",
    "    source_dirs = ['Raw'],\n",
    "    target_dir  = 'GT',\n",
    "    scale_gt = scale_gt,\n",
    "    axes        = 'ZYX' # z : channel , y : hight , x : width\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "X, Y, XY_axes = create_patches_reduced_target (\n",
    "    raw_data            = raw_data,\n",
    "    patch_size          = (None,patch_size,patch_size),\n",
    "    n_patches_per_image = n_patches_per_image,\n",
    "    target_axes         = 'YX',\n",
    "    reduction_axes      = 'Z',\n",
    "    scale_gt = scale_gt,\n",
    "    save_file           = f'{root_dir}/Train/SR/microtubules_SR_trainig.npz',\n",
    "    dfcan_data=False,\n",
    ")\n",
    "# Use os.path.join for path concatenation to avoid errors\n",
    "raw_folder_path = os.path.join(root_dir, 'Train', 'SR', 'Raw')\n",
    "gt_folder_path = os.path.join(root_dir, 'Train', 'SR', 'GT')\n",
    "\n",
    "# Count files in Raw and GT folders\n",
    "files_Raw = os.listdir(raw_folder_path)\n",
    "print(f\"Number of files in Raw Folder: {len(files_Raw)}\")\n",
    "\n",
    "files_GT = os.listdir(gt_folder_path)\n",
    "print(f\"Number of files in GT Folder: {len(files_GT)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c32eb4",
   "metadata": {},
   "source": [
    "### Create Validation Dataset\n",
    "- Note: the number of patches are much smaller as we are creating a very small dataset for tutorial purpose only. \n",
    "- for real training, the number of patches needs to be much larger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a4c844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================\n",
      "    3 raw images x    1 transformations   =     3 images\n",
      "    3 images     x    5 patches per image =    15 patches in total\n",
      "==================================================================\n",
      "Input data:\n",
      "dataset/microtubules/val/Train/SR: target='GT', sources=['Raw'], axes='ZYX', pattern='*.tif*'\n",
      "==================================================================\n",
      "Transformations:\n",
      "1 x Broadcast target image to the shape of source\n",
      "==================================================================\n",
      "128 x 128\n",
      "Patch size:\n",
      "9 x 128 x 128\n",
      "==================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:22<00:00,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to dataset/microtubules/val/Train/SR/microtubules_SR_trainig.npz.\n",
      "Number of files in Raw Folder: 3\n",
      "Number of files in GT Folder: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "root_dir = 'dataset/microtubules/val'\n",
    "create_folders_SR(root_dir, gt_filename=\"SIM_gt\",\n",
    "    raw_filename=\"RawSIMData_level_02\")\n",
    "\n",
    "# define parameter for creating image patches\n",
    "scale_gt = 2.0\n",
    "patch_size = 256 \n",
    "n_patches_per_image = 5\n",
    "\n",
    "# create image patches for trainig . \n",
    "raw_data = RawDataScaled.from_folder (\n",
    "    basepath    = f'{root_dir}/Train/SR',\n",
    "    source_dirs = ['Raw'],\n",
    "    target_dir  = 'GT',\n",
    "    scale_gt = scale_gt,\n",
    "    axes        = 'ZYX' # z : channel , y : hight , x : width\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "X_val, Y_val, XY_axes_val = create_patches_reduced_target (\n",
    "    raw_data            = raw_data,\n",
    "    patch_size          = (None,patch_size,patch_size),\n",
    "    n_patches_per_image = n_patches_per_image,\n",
    "    target_axes         = 'YX',\n",
    "    reduction_axes      = 'Z',\n",
    "    scale_gt = scale_gt,\n",
    "    save_file           = f'{root_dir}/Train/SR/microtubules_SR_trainig.npz',\n",
    "    dfcan_data=False,\n",
    ")\n",
    "# Use os.path.join for path concatenation to avoid errors\n",
    "raw_folder_path_val = os.path.join(root_dir, 'Train', 'SR', 'Raw')\n",
    "gt_folder_path_val = os.path.join(root_dir, 'Train', 'SR', 'GT')\n",
    "\n",
    "# Count files in Raw and GT folders\n",
    "files_Raw = os.listdir(raw_folder_path_val)\n",
    "print(f\"Number of files in Raw Folder: {len(files_Raw)}\")\n",
    "\n",
    "files_GT = os.listdir(gt_folder_path_val)\n",
    "print(f\"Number of files in GT Folder: {len(files_GT)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21513a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Information regarding training data\n",
      "----------------------------------\n",
      "shape of Input  Image  : X  (25, 1, 9, 128, 128)\n",
      "shape of Ground Truth Image : Y  (25, 1, 1, 256, 256)\n",
      "axes  of X , Y  SCZYX\n",
      "\n",
      "information regarding validation data\n",
      "----------------------------------\n",
      "shape of Input  Image  : X_val  (15, 1, 9, 128, 128)\n",
      "shape of Ground Truth Image : Y_val  (15, 1, 1, 256, 256)\n",
      "axes  of X_val , Y_val  SCZYX\n"
     ]
    }
   ],
   "source": [
    "print(' Information regarding training data')\n",
    "print('----------------------------------')\n",
    "print(\"shape of Input  Image  : X \", X.shape) \n",
    "print(\"shape of Ground Truth Image : Y \", Y.shape) \n",
    "print(\"axes  of X , Y \", XY_axes) \n",
    "print()\n",
    "print('information regarding validation data')\n",
    "print('----------------------------------')\n",
    "print(\"shape of Input  Image  : X_val \", X_val.shape)\n",
    "print(\"shape of Ground Truth Image : Y_val \", Y_val.shape)\n",
    "print(\"axes  of X_val , Y_val \", XY_axes_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec472669",
   "metadata": {},
   "source": [
    "## Visualization of the Image Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "771cef70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ca4167f3e441d2ac81913654665355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Index:', max=4), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_patches_on_demand(X, Y, num_slice =1):\n",
    "    def plot_patches(i):\n",
    "        plt.figure(figsize=(8, 4)) #H:W\n",
    "        sl = slice(i,  (i + num_slice)), 0\n",
    "        plot_some(X[sl], Y[sl], title_list=[np.arange(sl[0].start, sl[0].stop)])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "    i_slider = widgets.IntSlider(value=0, min=0, max=num_slice, description='Index:')\n",
    "    widgets.interact(plot_patches, i=i_slider)\n",
    "\n",
    "plot_patches_on_demand(X, Y, num_slice=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05663b56",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpc_thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
